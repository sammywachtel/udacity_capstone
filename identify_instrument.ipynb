{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for Training\n",
    "- Extract all the samples and generate spectrogram jpegs for each\n",
    "- Train a CNN on the jpegs\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info about training set\n",
      "283704\n",
      "['data/nsynth-train-spectrograms/vocal/vocal_acoustic_029-059-025.jpg']\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "['vocal']\n",
      "info about validation set\n",
      "12678\n",
      "categories are:  {'keyboard', 'brass', 'reed', 'vocal', 'organ', 'mallet', 'bass', 'guitar', 'string', 'flute'}\n",
      "['data/nsynth-valid-spectrograms/brass/brass_acoustic_006-076-025.jpg']\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "['brass']\n"
     ]
    }
   ],
   "source": [
    "from utils import general_utils\n",
    "import importlib\n",
    "importlib.reload(general_utils)\n",
    "\n",
    "train_files, train_targets, train_target_names = general_utils.load_dataset('data/nsynth-train-spectrograms')\n",
    "\n",
    "print('info about training set')\n",
    "print(len(train_files))\n",
    "print(train_files[500:501])\n",
    "print(train_targets[500:501])\n",
    "print(train_target_names[500:501])\n",
    "\n",
    "valid_files, valid_targets, valid_target_names = general_utils.load_dataset('data/nsynth-valid-spectrograms')\n",
    "\n",
    "print('info about validation set')\n",
    "print(len(valid_files))\n",
    "print('categories are: ', set(valid_target_names))\n",
    "print(valid_files[500:501])\n",
    "print(valid_targets[500:501])\n",
    "print(valid_target_names[500:501])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dataframe that will be part of the image generator construction\n",
    "#PART 1: zip the data\n",
    "import pandas as pd\n",
    "\n",
    "# merge the three arrays into an array of tupples\n",
    "train_data = list(zip(train_files, train_targets, train_target_names))\n",
    "valid_data = list(zip(valid_files, valid_targets, valid_target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2: to limit the size of the datasets, uncomment / change the code here\n",
    "\n",
    "train_data = train_data[:100000]\n",
    "valid_data = valid_data[:4300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3: Create the dataframes\n",
    "\n",
    "train_df = pd.DataFrame(train_data, columns = ['file_paths', 'targets', 'target_names'])\n",
    "valid_df = pd.DataFrame(valid_data, columns = ['file_paths', 'targets', 'target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (100000, 3)\n",
      "valid shape (4300, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train shape', train_df.shape)\n",
    "print('valid shape', valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# create the data generator\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "\n",
    "# make the training data generator\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        x_col='file_paths',\n",
    "        y_col='target_names',\n",
    "        batch_size=32,\n",
    "        seed=69,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical',\n",
    "        target_size=(64,64)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4300 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# make the validation data generator\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        x_col='file_paths',\n",
    "        y_col='target_names',\n",
    "        batch_size=32,\n",
    "        seed=69,\n",
    "        shuffle=True,\n",
    "        class_mode='categorical',\n",
    "        target_size=(64,64)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFULL THINGS\n",
    "\n",
    "#to go through all of the files to make sure they're finable\n",
    "#import os.path\n",
    "#for f in valid_files:#valid_generator.filepaths:\n",
    "#    if not os.path.exists(f):\n",
    "#        print(f, 'does not exist')\n",
    "\n",
    "# get all of the file paths in the data generator\n",
    "#generator_files = set(valid_generator.filepaths)\n",
    "\n",
    "# make sure all of the actual files are accounted for in the generator\n",
    "#i = 0\n",
    "#for f in valid_files:\n",
    "#    if f not in generator_files:\n",
    "#        print('N', f)\n",
    "#        i+=1\n",
    "    #else:\n",
    "        #print('Y', f)\n",
    "#print(i, 'files do not match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 20:40:53.132492 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0902 20:40:53.150637 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0902 20:40:53.153576 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0902 20:40:53.181541 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3661: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0902 20:40:53.191477 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:127: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0902 20:40:53.200397 139741414876992 deprecation.py:506] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0902 20:40:53.490862 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0902 20:40:53.499158 139741414876992 deprecation_wrapper.py:119] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3014: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,679,626\n",
      "Trainable params: 2,679,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Inspired by https://medium.com/gradientcrescent/urban-sound-classification-using-convolutional-neural-networks-with-keras-theory-and-486e92785df4\n",
    "\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(64,64,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0005, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_generator.n//train_generator.batch_size is 100000//32\n",
      "valid_generator.n//valid_generator.batch_size is 4300//32\n",
      "STEP_SIZE_TRAIN, STEP_SIZE_VALID is 3125, 134\n"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "print('train_generator.n//train_generator.batch_size is {}//{}'.format(train_generator.n, train_generator.batch_size))\n",
    "print('valid_generator.n//valid_generator.batch_size is {}//{}'.format(valid_generator.n, valid_generator.batch_size))\n",
    "print('STEP_SIZE_TRAIN, STEP_SIZE_VALID is {}, {}'.format(STEP_SIZE_TRAIN, STEP_SIZE_VALID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 20:40:53.633869 139741414876992 deprecation.py:323] From /home/ec2-user/anaconda3/envs/magenta-gpu/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0902 20:40:53.925768 139741414876992 variables.py:2445] Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 619s 198ms/step - loss: 1.0778 - acc: 0.6105 - val_loss: 1.0974 - val_acc: 0.6663\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.09736, saving model to saved_models/weights.best.v1.hdf5\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 543s 174ms/step - loss: 0.6885 - acc: 0.7587 - val_loss: 1.0511 - val_acc: 0.7083\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.09736 to 1.05106, saving model to saved_models/weights.best.v1.hdf5\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 542s 174ms/step - loss: 0.6051 - acc: 0.7920 - val_loss: 1.0209 - val_acc: 0.6792\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.05106 to 1.02092, saving model to saved_models/weights.best.v1.hdf5\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 542s 173ms/step - loss: 0.5889 - acc: 0.8022 - val_loss: 1.1566 - val_acc: 0.6799\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.02092\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 542s 174ms/step - loss: 0.5984 - acc: 0.8028 - val_loss: 1.1662 - val_acc: 0.6795\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.02092\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 542s 173ms/step - loss: 0.6152 - acc: 0.7995 - val_loss: 1.0850 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.02092\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 541s 173ms/step - loss: 0.6519 - acc: 0.7905 - val_loss: 1.1565 - val_acc: 0.6647\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.02092\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 542s 174ms/step - loss: 0.6961 - acc: 0.7782 - val_loss: 1.0742 - val_acc: 0.6657\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.02092\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 543s 174ms/step - loss: 0.7509 - acc: 0.7630 - val_loss: 1.0831 - val_acc: 0.6589\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.02092\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 544s 174ms/step - loss: 0.8093 - acc: 0.7455 - val_loss: 1.0130 - val_acc: 0.6570\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.02092 to 1.01305, saving model to saved_models/weights.best.v1.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.00830357752901, 0.6572164948453608]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.v1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10,\n",
    "                    callbacks=[checkpointer]\n",
    ")\n",
    "model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
